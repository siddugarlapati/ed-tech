# EdTech-Optimized Configuration for Advanced QLoRA System
# Specifically tuned for educational technology platforms

model:
  model_name_or_path: "meta-llama/Llama-3.1-8B"  # Excellent for educational explanations
  trust_remote_code: false
  torch_dtype: "bfloat16"
  attn_implementation: "flash_attention_2"
  
  # Memory-efficient for educational deployment
  load_in_4bit: true
  bnb_4bit_compute_dtype: "bfloat16"
  bnb_4bit_quant_type: "nf4"
  bnb_4bit_use_double_quant: true
  bnb_4bit_quant_storage: "uint8"
  
  device_map: "auto"
  low_cpu_mem_usage: true

lora:
  r: 32                    # Balanced for educational content
  alpha: 32               # 1:1 ratio for stability
  dropout: 0.05           # Low dropout for consistent responses
  bias: "none"
  task_type: "CAUSAL_LM"
  use_rslora: true        # Better stability for tutoring
  use_dora: false
  init_lora_weights: true

data:
  # Support multiple educational data formats
  max_seq_length: 2048    # Good for detailed explanations
  truncation: true
  padding: "max_length"
  min_length: 20          # Ensure substantial educational responses
  max_length: 3000        # Allow detailed explanations
  filter_duplicates: true

training:
  output_dir: "./models/edtech_model"
  run_name: "edtech_production"
  
  # Training schedule optimized for educational content
  num_train_epochs: 4     # More epochs for better educational responses
  per_device_train_batch_size: 1
  per_device_eval_batch_size: 1
  gradient_accumulation_steps: 16
  
  # Optimization for educational stability
  learning_rate: 1.0e-4   # Lower LR for stable educational responses
  weight_decay: 0.01
  adam_beta1: 0.9
  adam_beta2: 0.999
  max_grad_norm: 1.0
  optim: "paged_adamw_8bit"
  
  # Learning rate scheduling
  lr_scheduler_type: "cosine"
  warmup_ratio: 0.05      # Longer warmup for educational content
  
  # Evaluation and saving
  evaluation_strategy: "steps"
  eval_steps: 100
  save_strategy: "steps"
  save_steps: 100
  save_total_limit: 5
  load_best_model_at_end: true
  metric_for_best_model: "eval_loss"
  
  # Performance optimizations
  dataloader_num_workers: 4
  dataloader_pin_memory: true
  gradient_checkpointing: true
  fp16: false
  bf16: true
  tf32: true
  
  # Logging for educational monitoring
  logging_steps: 10
  report_to: ["tensorboard"]
  
  # Educational-specific features
  group_by_length: true
  remove_unused_columns: false
  
  # No noise injection for consistent educational responses
  neftune_noise_alpha: null

# EdTech-specific settings
edtech:
  # Content safety and appropriateness
  content_filter: true
  age_appropriate: true
  educational_standards: ["Common Core", "NGSS", "State Standards"]
  
  # Supported subjects
  subjects:
    - "Mathematics"
    - "Science" 
    - "English Language Arts"
    - "Social Studies"
    - "Computer Science"
    - "Foreign Languages"
  
  # Grade levels
  grade_levels:
    - "Elementary (K-5)"
    - "Middle School (6-8)" 
    - "High School (9-12)"
    - "College/University"
  
  # Learning objectives
  bloom_taxonomy:
    - "Remember"
    - "Understand"
    - "Apply"
    - "Analyze"
    - "Evaluate"
    - "Create"
  
  # Assessment types
  assessment_types:
    - "Multiple Choice"
    - "Short Answer"
    - "Essay"
    - "Performance Task"
    - "Portfolio"
  
  # Differentiation strategies
  differentiation:
    - "Visual Learners"
    - "Auditory Learners"
    - "Kinesthetic Learners"
    - "Advanced Learners"
    - "Struggling Learners"
    - "English Language Learners"
    - "Special Needs"

# Deployment settings for EdTech platforms
deployment:
  # API settings
  api:
    rate_limit: 100         # requests per minute per user
    max_tokens: 2048        # maximum response length
    timeout: 30             # seconds
    
  # Safety and moderation
  safety:
    content_moderation: true
    profanity_filter: true
    age_verification: true
    parental_controls: true
    
  # Privacy and compliance
  privacy:
    data_retention: "30 days"
    anonymize_data: true
    gdpr_compliant: true
    coppa_compliant: true   # Children's Online Privacy Protection Act
    ferpa_compliant: true   # Family Educational Rights and Privacy Act
    
  # Performance monitoring
  monitoring:
    response_time_target: "< 2 seconds"
    uptime_target: "99.9%"
    error_rate_target: "< 0.1%"
    
  # Scaling
  scaling:
    min_replicas: 2
    max_replicas: 10
    cpu_threshold: 70
    memory_threshold: 80